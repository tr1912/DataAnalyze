# 模型超参数

* 在KNN的算法介绍中发现：k值的不同会导致模型分类结果不同。
* 因此k值会影响整个分类结果
* 所以k值被称为KNN模型的超参数

如何对超参数取值？
## 学习曲线

可以通过学习曲线寻找模型的最优超参数
![[Pasted image 20241127014417.png]]

找到曲线中最高点对应的k值

``` python
# 读取原数据
data = pd.read_csv('./datesets/datingTestSet.txt', sep='\t', header=None)
data.head()

# 提取样本数据
feature = data[[0,1,2]]
target = data[3]

# 数据集切分
x_train,x_test,y_train,y_test = train_test_split(feature,target, test_size=0.2,random_state=2020)

import numpy as np
import matplotlib.pyplot as plt
# 通过学习曲线寻找模型最佳超参数值
ks = np.linspace(2,100,num=50).astype('int')
scores = []  # 每个k值对应的模型分值

for k in ks:
	model=KNeighborsClassifier(n_neighbors=k)
	model.fit(x_train,y_train)
	score = model.score(x_test,y_test)
	scores.append(score)


scores = np.array(scores)

# 绘制学习曲线
plt.plot(ks,scores)
plt.xlabel('k')
plt.ylabel('score')

# 寻找最大分值对应的k值
max_index = np.argmax(scores)
max_index
best_k = ks[max_index]
best_k

# 使用最佳的超参数进行建模
knn = KNeighborsClassifier(n_neighbors=best_k)
knn.fit(x_train,y_train)
knn.score(x_test,y_test)
```
![[Pasted image 20241127015213.png]]

## k折交叉验证

目的：选出最为合适的模型超参数的数值，然后将超参数的值作用到模型的创建中
![[Pasted image 20241127015632.png]]


实现思路：
	1. 将训练数据均分成k等份
	2. 使用1分数据作为验证数据，其余作为训练数据
	3. 计算验证准确率
	4. 使用不同的测试集，重复2,3步骤
	5. 对准确率做平均，作为对未知数据预测准确率的估计
![[Pasted image 20241127020037.png]]

``` python
# 读取原数据
data = pd.read_csv('./datesets/datingTestSet.txt', sep='\t', header=None)
data.head()

# 提取样本数据
feature = data[[0,1,2]]
target = data[3]

# 数据集切分
x_train,x_test,y_train,y_test = train_test_split(feature,target, test_size=0.2,random_state=2020)

# 交叉验证
from sklearn.model_selection import cross_val_score
model=KNeighborsClassifier(n_neighbors=3)
cross_val_score(model,x_train,y_train,cv=5).mean()

# 基于交叉验证进行模型最佳超参数的寻找
import numpy as np
import matplotlib.pyplot as plt
# 通过学习曲线寻找模型最佳超参数值
ks = np.linspace(2,100,num=50).astype('int')
scores = []  # 每个k值对应的模型分值

for k in ks:
	model=KNeighborsClassifier(n_neighbors=k)
	score = cross_val_score(model,x_train,y_train,cv=5).mean()
	scores.append(score)

scores = np.array(scores)
# 绘制学习曲线
plt.plot(ks,scores)
plt.xlabel('k')
plt.ylabel('score')

# 寻找最大分值对应的k值
max_index = np.argmax(scores)
max_index

best_k = ks[max_index]
best_k
```


