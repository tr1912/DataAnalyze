需求：
	基于400张共计40种人脸图片对模型进行训练，最终使得模型可以准去识别到每一个人的照片

记录关键步骤

``` python
# 随机抽取一个人脸的照片数据进行读取
import matplotlib.pylab as plt
img_arr = plt.imread('./datasets/faces/刘梅/3.bmp')
img_arr.shape  #读取出来照片是一个三维数组

## 人脸照片是不需要颜色进行相关的区分，因此将人脸图片的三维数据中的颜色通道可以过滤掉
plt.imshow(img_arr)
#过滤图片的颜色通道从而减少图片的特征维度
img_arr = img_arr[:,:,0]
img_arr.shape
# 灰度显示
plt.imshow(img_arr,cmap='gray')
#批量读取图片相关数据，进行样本数据的提取
import numpy as np
import os
feature = []  #保存特征数据（像素点）
target = []   #保存标签数据（人名）
# 获取每个人名的文件夹名称，完整图片路径 './datasets/faces/刘梅/3.bmp'
# listdir作用是可以将一个文件夹下所有文件的名称获取
names = os.listdir('./datasets/faces')
for name in names:
	if name!='.DS_Store':
		for index in range(10):  #index取值范围0~9
			img_path = './datasets/faces/'+name+'/'+str(index)+'.bmp'
			# 根据图片路径将图片的像素点进行读取
			img_arr = plt.imread(img_path)
			# 过滤图片颜色通道
			img_arr = img_arr[:,:,0] #img_arr的形状是(64,64)
			feature.append(img_arr)
			target.append(name)
#数组化
feature = np.array(feature)
target = np.array(target)
feature.shape
#(400,64,64)
#发现样本的特征是三维：有问题吗？训练模型的时候，模型只可以接收二维形式的特征矩阵
# 将样本数据从三维变成二维
feauture = feauture.reshape((400,4096))
# 数据集切分
from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(feature,target, test_size=0.2,random_state=2020)

# 寻找模型最优的超参数
from sklearn.model_selection import cross_val_score
from sklearn.neighbors import KNeighborsClassifier

ks = np.linspace(3,100,num=30).astype('int')
scores=[]
for k in ks:
	model = KNeighborsClassifier(n_neighbors=k)
	score = cross_val_score(model,x_train,y_train,cv=5).mean()
	scores.append(score)
scores = np.array(scores)
index = np.argmax(scores)
best_k = ks[index]
# 建模
model = KNeighborsClassifier(n_neighbors=best_k)
model.fit(x_train,y_train)
model.score(x_test,y_test)

# 使用训练好的模型进行人脸识别任务
persons=x_test[10:15]
print('真实的名字：',y_test[10:15])
print('模型识别的人名：',model.predict(persons))

```